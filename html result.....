from bs4 import BeautifulSoup
import re
import os
import json

def extract_strengths_weaknesses(html_file_path):
    """Extract strengths and weaknesses from a single HTML file."""
    with open(html_file_path, 'r', encoding='utf-8') as file:
        soup = BeautifulSoup(file.read(), 'html.parser')
    
    return extract_from_soup(soup)

def extract_from_html_content(html_content):
    """Extract strengths and weaknesses from HTML content string."""
    soup = BeautifulSoup(html_content, 'html.parser')
    return extract_from_soup(soup)

def clean_text(text):
    """Clean and normalize text content."""
    if not text:
        return ""
    
    # Remove extra whitespace and normalize
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    # Remove leading/trailing colons
    text = text.strip(':').strip()
    
    return text

def is_bold_element(element):
    """Check if element has bold styling using various methods."""
    # Method 1: Check style attribute for font-weight
    style = element.get('style', '')
    if 'font-weight' in style and ('bold' in style or '700' in style or 'bolder' in style):
        return True
    
    # Method 2: Check for bold tags (strong, b)
    if element.name in ['strong', 'b']:
        return True
    
    # Method 3: Check class attribute
    classes = element.get('class', [])
    for cls in classes:
        if 'bold' in cls.lower():
            return True
    
    return False

def extract_from_soup(soup):
    """Extract strengths and weaknesses using text-based approach to avoid section mixing."""
    
    # Get the full text content
    full_text = soup.get_text()
    
    # Clean up the text
    full_text = re.sub(r'\s+', ' ', full_text)
    
    print(f"📄 Document length: {len(full_text)} characters")
    
    # Find the Key Rating Drivers section
    section_start = -1
    section_end = len(full_text)
    
    # Look for the start
    start_patterns = [
        r'Key Rating Drivers[^a-zA-Z]*Detailed Description',
        r'Key Rating Drivers',
        r'Strengths\s*:'
    ]
    
    for pattern in start_patterns:
        match = re.search(pattern, full_text, re.IGNORECASE)
        if match:
            section_start = match.start()
            print(f"✅ Found section start at position {section_start} using pattern: {pattern}")
            break
    
    if section_start == -1:
        print("❌ Could not find Key Rating Drivers section")
        return {}, {}
    
    # Look for the end
    end_patterns = [
        r'Liquidity\s*:',
        r'Outlook\s*:',
        r'Analytical Approach',
        r'About the Company'
    ]
    
    for pattern in end_patterns:
        match = re.search(pattern, full_text[section_start:], re.IGNORECASE)
        if match:
            section_end = section_start + match.start()
            print(f"✅ Found section end at position {section_end} using pattern: {pattern}")
            break
    
    # Extract the target section
    target_text = full_text[section_start:section_end]
    print(f"🎯 Target section: {len(target_text)} characters")
    
    # Now extract strengths and weaknesses from this clean text
    strengths_dict, weaknesses_dict = extract_sections_from_text(target_text)
    
    return strengths_dict, weaknesses_dict

def extract_sections_from_text(text):
    """Extract strengths and weaknesses from clean text using clear boundaries."""
    
    strengths_dict = {}
    weaknesses_dict = {}
    
    # Find strengths section
    strengths_match = re.search(r'Strengths?\s*:?\s*(.*?)(?=Weakness|Liquidity|Outlook|$)', 
                               text, re.DOTALL | re.IGNORECASE)
    
    if strengths_match:
        strengths_text = strengths_match.group(1).strip()
        print(f"📈 Found strengths section: {len(strengths_text)} characters")
        print(f"📄 Strengths preview: {strengths_text[:200]}...")
        
        strengths_dict = parse_bullet_points(strengths_text, "Strengths")
    else:
        print("❌ No strengths section found")
    
    # Find weaknesses section
    weakness_match = re.search(r'Weakness(?:es)?\s*:?\s*(.*?)(?=Liquidity|Outlook|Analytical|$)', 
                              text, re.DOTALL | re.IGNORECASE)
    
    if weakness_match:
        weakness_text = weakness_match.group(1).strip()
        print(f"📉 Found weaknesses section: {len(weakness_text)} characters")
        print(f"📄 Weaknesses preview: {weakness_text[:200]}...")
        
        weaknesses_dict = parse_bullet_points(weakness_text, "Weaknesses")
    else:
        print("❌ No weaknesses section found")
    
    return strengths_dict, weaknesses_dict

def parse_bullet_points(section_text, section_name):
    """Parse bullet points from section text into key-value pairs."""
    
    print(f"\n🔍 Parsing {section_name}...")
    items = {}
    
    if not section_text or len(section_text) < 20:
        print(f"⚠️ Section text too short: {len(section_text)} characters")
        return items
    
    # Method 1: Split by sentences that end with period and start with capital letter
    print("   Trying Method 1: Sentence-based splitting...")
    
    # Look for patterns like "Title: Description. Next Title: Next Description."
    sentences = re.split(r'(?<=\.)\s+(?=[A-Z])', section_text)
    
    for i, sentence in enumerate(sentences):
        sentence = sentence.strip()
        
        if len(sentence) < 20:  # Skip very short sentences
            continue
            
        if ':' in sentence:
            # Split on first colon
            colon_pos = sentence.find(':')
            title = sentence[:colon_pos].strip()
            description = sentence[colon_pos+1:].strip()
            
            # Validate title
            if (len(title) > 5 and len(title) < 200 and 
                not title.lower().startswith(('the ', 'this ', 'it ', 'there ', 'these ')) and
                not title.lower() in ['strengths', 'weaknesses', 'weakness']):
                
                title = clean_text(title)
                description = clean_text(description)
                
                if title:  # Only add if title is not empty after cleaning
                    items[title] = description
                    print(f"   ✅ Found: {title[:50]}...")
    
    # Method 2: If Method 1 didn't work well, try paragraph-based approach
    if len(items) == 0:
        print("   Trying Method 2: Paragraph-based splitting...")
        
        # Split by double newlines, multiple spaces, or other paragraph indicators
        paragraphs = re.split(r'\n\s*\n|\.\s{2,}', section_text)
        
        for para in paragraphs:
            para = para.strip()
            
            if len(para) < 20 or ':' not in para:
                continue
                
            colon_pos = para.find(':')
            title = para[:colon_pos].strip()
            description = para[colon_pos+1:].strip()
            
            if (len(title) > 5 and len(title) < 200 and
                not title.lower() in ['strengths', 'weaknesses', 'weakness']):
                
                title = clean_text(title)
                description = clean_text(description)
                
                if title:
                    items[title] = description
                    print(f"   ✅ Found: {title[:50]}...")
    
    # Method 3: Pattern-based extraction for common rating document patterns
    if len(items) == 0:
        print("   Trying Method 3: Pattern-based extraction...")
        
        patterns = [
            r'(Strong [^:]{10,150}):\s*([^.]+(?:\.[^.]*)*)',
            r'(Robust [^:]{10,150}):\s*([^.]+(?:\.[^.]*)*)',
            r'(Exposure to [^:]{10,150}):\s*([^.]+(?:\.[^.]*)*)',
            r'(Well-positioned [^:]{10,150}):\s*([^.]+(?:\.[^.]*)*)',
            r'([A-Z][^:]{15,150}):\s*([^.]+(?:\.[^.]*){1,})'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, section_text, re.DOTALL)
            for match in matches:
                title = clean_text(match.group(1))
                description = clean_text(match.group(2))
                
                if (title and len(title) > 5 and len(title) < 200 and
                    not title.lower() in ['strengths', 'weaknesses', 'weakness']):
                    
                    items[title] = description
                    print(f"   ✅ Found: {title[:50]}...")
    
    print(f"📊 {section_name} parsed: {len(items)} items found")
    return items

def debug_html_structure(html_file_path):
    """Debug function to understand HTML structure."""
    with open(html_file_path, 'r', encoding='utf-8') as file:
        soup = BeautifulSoup(file.read(), 'html.parser')
    
    print("🔍 DEBUGGING HTML STRUCTURE")
    print("=" * 50)
    
    full_text = soup.get_text()
    full_text = re.sub(r'\s+', ' ', full_text)
    
    print(f"📊 Total document length: {len(full_text)} characters")
    
    # Check for key terms
    key_terms = {
        'Key Rating Drivers': full_text.count('Key Rating Drivers'),
        'Strengths': full_text.count('Strengths'),
        'Weaknesses': full_text.count('Weaknesses'),
        'Weakness': full_text.count('Weakness'),
        'Liquidity': full_text.count('Liquidity'),
        'Outlook': full_text.count('Outlook')
    }
    
    print("\n📍 Key terms found:")
    for term, count in key_terms.items():
        print(f"   {term}: {count} occurrences")
    
    # Show text around strengths
    strengths_pos = full_text.lower().find('strengths')
    if strengths_pos > -1:
        print(f"\n📄 Text around 'Strengths' (position {strengths_pos}):")
        start = max(0, strengths_pos - 100)
        end = min(len(full_text), strengths_pos + 300)
        sample = full_text[start:end]
        print(f"...{sample}...")
    
    # Show text around weakness
    weakness_pos = full_text.lower().find('weakness')
    if weakness_pos > -1:
        print(f"\n📄 Text around 'Weakness' (position {weakness_pos}):")
        start = max(0, weakness_pos - 100)
        end = min(len(full_text), weakness_pos + 300)
        sample = full_text[start:end]
        print(f"...{sample}...")

def process_folder(folder_path):
    """Process all HTML files in a folder."""
    all_results = {}
    
    # Find all HTML files
    html_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.html', '.htm'))]
    
    print(f"📁 Found {len(html_files)} HTML files")
    
    # Process each file
    for filename in html_files:
        file_path = os.path.join(folder_path, filename)
        try:
            print(f"\n{'='*60}")
            print(f"🔄 Processing: {filename}")
            print(f"{'='*60}")
            
            strengths, weaknesses = extract_strengths_weaknesses(file_path)
            
            file_key = filename.replace('.html', '').replace('.htm', '')
            all_results[file_key] = {
                'strengths': strengths,
                'weaknesses': weaknesses
            }
            
            print(f"\n✅ Completed {filename}:")
            print(f"   📈 Strengths: {len(strengths)}")
            print(f"   📉 Weaknesses: {len(weaknesses)}")
            
        except Exception as e:
            print(f"❌ Error with {filename}: {e}")
            import traceback
            traceback.print_exc()
    
    return all_results

def save_and_print_results(results):
    """Save to JSON and print summary."""
    # Clean results to remove empty keys
    cleaned_results = {}
    
    for filename, data in results.items():
        cleaned_strengths = {}
        cleaned_weaknesses = {}
        
        # Clean strengths
        for key, value in data['strengths'].items():
            key = clean_text(key)
            value = clean_text(value)
            if key and len(key) > 3:  # Only keep meaningful keys
                cleaned_strengths[key] = value
        
        # Clean weaknesses  
        for key, value in data['weaknesses'].items():
            key = clean_text(key)
            value = clean_text(value)
            if key and len(key) > 3:  # Only keep meaningful keys
                cleaned_weaknesses[key] = value
        
        cleaned_results[filename] = {
            'strengths': cleaned_strengths,
            'weaknesses': cleaned_weaknesses
        }
    
    # Save to JSON
    with open('extracted_results.json', 'w', encoding='utf-8') as f:
        json.dump(cleaned_results, f, indent=2, ensure_ascii=False)
    
    # Print detailed summary
    print(f"\n{'='*80}")
    print("📊 FINAL RESULTS SUMMARY")
    print(f"{'='*80}")
    
    total_strengths = 0
    total_weaknesses = 0
    
    for filename, data in cleaned_results.items():
        strengths_count = len(data['strengths'])
        weaknesses_count = len(data['weaknesses'])
        
        total_strengths += strengths_count
        total_weaknesses += weaknesses_count
        
        print(f"\n📄 {filename}:")
        print(f"   📈 Strengths: {strengths_count}")
        print(f"   📉 Weaknesses: {weaknesses_count}")
        
        # Print strengths
        if data['strengths']:
            print(f"\n   🔹 STRENGTHS:")
            for i, (key, value) in enumerate(data['strengths'].items(), 1):
                print(f"      {i}. {key}")
                if value:
                    print(f"         → {value[:100]}{'...' if len(value) > 100 else ''}")
                print()
        
        # Print weaknesses
        if data['weaknesses']:
            print(f"   🔸 WEAKNESSES:")
            for i, (key, value) in enumerate(data['weaknesses'].items(), 1):
                print(f"      {i}. {key}")
                if value:
                    print(f"         → {value[:100]}{'...' if len(value) > 100 else ''}")
                print()
    
    print(f"\n📊 TOTALS:")
    print(f"   📈 Total Strengths: {total_strengths}")
    print(f"   📉 Total Weaknesses: {total_weaknesses}")
    print(f"   📁 Files Processed: {len(cleaned_results)}")
    
    print(f"\n💾 Results saved to 'extracted_results.json'")

if __name__ == "__main__":
    folder_path = 'html_files'
    
    # Check if folder exists
    if not os.path.exists(folder_path):
        print(f"❌ Folder '{folder_path}' not found!")
        exit()
    
    # Debug first file
    html_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.html', '.htm'))]
    if html_files:
        print("🔍 Debugging first HTML file structure...")
        debug_html_structure(os.path.join(folder_path, html_files[0]))
        print("\n" + "="*80)
        
        # Ask user if they want to continue
        response = input("\n🤔 Continue with processing all files? (y/n): ").lower()
        if response != 'y':
            print("👋 Exiting...")
            exit()
    
    # Process all files
    print("\n🚀 Processing all HTML files...")
    results = process_folder(folder_path)
    
    if results:
        save_and_print_results(results)
    else:
        print("❌ No HTML files found or processed successfully!")
